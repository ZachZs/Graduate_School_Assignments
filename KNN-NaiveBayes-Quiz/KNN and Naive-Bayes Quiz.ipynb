{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b><font color=\"#3c38a8\">Quiz \\#1 - KNN and Naive-Bayes</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Make the random data\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Naive-Bayes\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "#KNN\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#3c38a8\">Create Functions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_func(df):\n",
    "    # initialize encoder\n",
    "    encode = preprocessing.OneHotEncoder()\n",
    "    # fit the encoder to the categorical features\n",
    "    encode.fit(df)\n",
    "    # create an array of the encoded features\n",
    "    onehotlabels = encode.transform(df).toarray()\n",
    "    # turn the array into a dataframe\n",
    "    work_data = onehotlabels\n",
    "    # return the array\n",
    "    return work_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(onehotlabels, y):\n",
    "\n",
    "    # create the classifier\n",
    "    clf = ComplementNB()\n",
    "    \n",
    "    # clf = MultinomialNB() -> Note: running this classifier resulted in data that only had y_pred values of 0; a\n",
    "    # cause was looked for extensively but could not be found, so the ComplementNB() was used instead (since it \n",
    "    # gave actual values)\n",
    "\n",
    "    # fit the classifier to the features and the label\n",
    "    clf.fit(onehotlabels, y)\n",
    "\n",
    "    # create a prediction\n",
    "    y_pred = clf.predict(onehotlabels)\n",
    "    \n",
    "    # create an f1 score for the data\n",
    "    f_one = f1_score(y , y_pred)\n",
    "    \n",
    "    # return the f1 score\n",
    "    return f_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k, features, y):\n",
    "    # Create the classifier baased on k neighbors and fit it to the data along with correct labels\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k, algorithm = 'kd_tree', p=2)  \n",
    "    classifier.fit(features, y)\n",
    "            \n",
    "    # create a prediction based on just features\n",
    "    y_pred = classifier.predict(features)\n",
    "            \n",
    "    # find the F1 score and append it to the list\n",
    "    f_one = f1_score(y , y_pred)\n",
    "    \n",
    "    # return the fl score\n",
    "    return f_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#3c38a8\">Create Randomized Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the creation of the data\n",
    "X, y = make_classification(n_samples=10000,\n",
    "                           random_state=528552,\n",
    "                           class_sep=0.65,\n",
    "                           flip_y=0.15,\n",
    "                           weights=[0.65, 0.35],\n",
    "                           n_features=10,\n",
    "                           n_informative=4,\n",
    "                           n_redundant=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank list\n",
    "col_list = []\n",
    "\n",
    "# loop through 10 iterations and create a label for each of the 10 columns\n",
    "for i in range(1,11):\n",
    "    col_list.append('cont'+str(i))\n",
    "\n",
    "# Check the list\n",
    "col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of X with col_lsit as column names\n",
    "df1 = pd.DataFrame(X, columns = col_list)\n",
    "\n",
    "# cerate a datafrrame of y with the label 'y'\n",
    "df2 = pd.DataFrame(y, columns = ['y'])\n",
    "\n",
    "# join the dataframes together\n",
    "data = pd.concat([df2, df1],axis = 1)\n",
    "\n",
    "# check the dataframe\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['cont2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['cont4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['cont5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['cont7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['cont10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 categorical categories by splitting the continuous features based on distributions\n",
    "data[\"cat1\"] = pd.cut(data['cont2'], [-10,-0.7,10], labels = ['A', 'B'])\n",
    "data[\"cat2\"] = pd.cut(data['cont4'], [-10,0,10], labels = ['A', 'B'])\n",
    "data[\"cat3\"] = pd.cut(data['cont5'], [-10,-0.7,0.5,10], labels = ['A', 'B', 'C'])\n",
    "data[\"cat4\"] = pd.cut(data['cont7'], [-10,0.2,10], labels = ['A', 'B'])\n",
    "data[\"cat5\"] = pd.cut(data['cont10'], [-10,-0.7,0.7,10], labels = ['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the 5 categorical features and check the number of values in each class\n",
    "for i in range(1,6):\n",
    "    name = \"cat\" + str(i)\n",
    "    print(\"Categorical Variable \" + str(i))\n",
    "    print(data[name].value_counts())\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Standardized Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of just the continuous data\n",
    "cont_var = data.iloc[:,1:11]\n",
    "cont_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the seleted features\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(cont_var)\n",
    "X_scaled = scaler.transform(cont_var)\n",
    "\n",
    "# check to ensure everything looks good\n",
    "print(X_scaled.shape)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list for the col names\n",
    "scaled_cols = []\n",
    "\n",
    "# loop through the number of cols and add a title and number\n",
    "for i in range(1,11):\n",
    "    scaled_cols.append('scaled_cont'+str(i))\n",
    "\n",
    "# create a dataframe of the scaled array, along with the col names\n",
    "scaled_df = pd.DataFrame(X_scaled, columns = scaled_cols)\n",
    "\n",
    "# join the main dataframe with this new dataframe of scaled continuous values\n",
    "data = pd.concat([data, scaled_df],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataframe\n",
    "print(data.columns)\n",
    "print(data.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#3c38a8\">Run Naive-Bayes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the categorical features\n",
    "cat_features = list(data.iloc[:,11:16])\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Loops for the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the excel template\n",
    "nb_df = pd.DataFrame(columns=['Your Name',\n",
    "                               'Random State',\n",
    "                               'Class Separator',\n",
    "                               'flip_y',\n",
    "                               'Class weight',\n",
    "                               'Algorithm',\n",
    "                               'k-Neighbors',\n",
    "                               'Type_Features',\n",
    "                               'Number_features',\n",
    "                               'Number of Models',\n",
    "                               'Best F1 Score'])\n",
    "nb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank list for the scores\n",
    "score = []\n",
    "\n",
    "# create a y variable for the actual labels\n",
    "y = data[\"y\"]\n",
    "\n",
    "# for the number of features to check in the range of 1 to 5\n",
    "for i in range(1,6):\n",
    "    # if 1 or 4 features\n",
    "    if i == 1 or i == 4:\n",
    "        # do 5 samples\n",
    "        for j in range(1,6):\n",
    "            # select random categorical features, and make a dataframe of them\n",
    "            features = data[random.sample(cat_features,i)].values\n",
    "            \n",
    "            # Run the encoding function on the selected features -> returns array of encoded cols\n",
    "            onehotlabels = encoding_func(features)\n",
    "            \n",
    "            # run the naive-bayes equation on the array, and the correct labels\n",
    "            f_one = NB(onehotlabels, y)\n",
    "        \n",
    "            # add the f1 score to the list\n",
    "            score.append(f_one)\n",
    "        \n",
    "        # Create a row for the dataframe for the specific i, alongwith the max F1 score, then append to df\n",
    "        temp = pd.DataFrame([['Name',528552,0.65,0.15,'0.65, 0.35','NB','NA','Categorical',i,5,max(score)]],\n",
    "                           columns=list(nb_df.columns))\n",
    "        nb_df = nb_df.append(temp)\n",
    "        \n",
    "        # reset the score list\n",
    "        score = []\n",
    "        \n",
    "    elif i == 5:\n",
    "        # do 1 sample\n",
    "        # select random categorical features, and make a dataframe of them\n",
    "        features = data[random.sample(cat_features,i)].values\n",
    "            \n",
    "        # Run the encoding function on the selected features -> returns array of encoded cols\n",
    "        onehotlabels = encoding_func(features)\n",
    "            \n",
    "        # run the naive-bayes equation on the array, and the correct labels\n",
    "        f_one = NB(onehotlabels, y)\n",
    "        \n",
    "        # add the f1 score to the list\n",
    "        score.append(f_one)\n",
    "        \n",
    "        # Create a row for the dataframe for the specific i, alongwith the max F1 score, then append to df\n",
    "        temp = pd.DataFrame([['Name',528552,0.65,0.15,'0.65, 0.35','NB','NA','Categorical',i,1,max(score)]],\n",
    "                           columns=list(nb_df.columns))\n",
    "        nb_df = nb_df.append(temp)\n",
    "        \n",
    "        # reset the score list\n",
    "        score = []      \n",
    "    else:\n",
    "        # do 10 samples\n",
    "        for j in range(1,11):\n",
    "            # select random categorical features, and make a dataframe of them\n",
    "            features = data[random.sample(cat_features,i)].values\n",
    "            \n",
    "            # Run the encoding function on the selected features -> returns array of encoded cols\n",
    "            onehotlabels = encoding_func(features)\n",
    "            \n",
    "            # run the naive-bayes equation on the array, and the correct labels\n",
    "            f_one = NB(onehotlabels, y)\n",
    "        \n",
    "            # add the f1 score to the list\n",
    "            score.append(f_one)\n",
    "        \n",
    "        # Create a row for the dataframe for the specific i, alongwith the max F1 score, then append to df\n",
    "        temp = pd.DataFrame([['Name',528552,0.65,0.15,'0.65, 0.35','NB','NA','Categorical',i,10,max(score)]],\n",
    "                           columns=list(nb_df.columns))\n",
    "        nb_df = nb_df.append(temp)\n",
    "        \n",
    "        # reset the score list\n",
    "        score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#3c38a8\">Run KNN (Continuous)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the scaled numeric features\n",
    "num_features = list(data.columns)[16:26]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Loops for the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the excel template\n",
    "knn_df1 = pd.DataFrame(columns=['Your Name',\n",
    "                               'Random State',\n",
    "                               'Class Separator',\n",
    "                               'flip_y',\n",
    "                               'Class weight',\n",
    "                               'Algorithm',\n",
    "                               'k-Neighbors',\n",
    "                               'Type_Features',\n",
    "                               'Number_features',\n",
    "                               'Number of Models',\n",
    "                               'Best F1 Score'])\n",
    "knn_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank list for the scores\n",
    "score = []\n",
    "\n",
    "# create a y variable for the actual labels\n",
    "y = data[\"y\"]\n",
    "\n",
    "# Loop through each k value for # of neighbors\n",
    "for k in range(3,10,2):\n",
    "    # loop through each number of features as i\n",
    "    for i in range(3,8):\n",
    "        #loop through 100 samples\n",
    "        for j in range(1,101):\n",
    "            # select random continuous features, and make a datframe of them\n",
    "            features = data[random.sample(num_features,i)].values\n",
    "            \n",
    "            # Run the knn function, sending # neighbors, features, and the labels -> returns f1 score\n",
    "            f_one = knn(k, features, y)\n",
    "            \n",
    "            # add the f1 score to the list\n",
    "            score.append(f_one)\n",
    "        \n",
    "        # Create a row for the dataframe for the specific k and i, alongwith the max F1 score, then append to df\n",
    "        temp = pd.DataFrame([['Name',528552,0.65,0.15,'0.65, 0.35','KNN',k,'Continuous',i,100,max(score)]],\n",
    "                           columns=list(knn_df1.columns))\n",
    "        knn_df1 = knn_df1.append(temp)\n",
    "        \n",
    "        # reset the score list\n",
    "        score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#3c38a8\">Run KNN (Continuous + Categorical)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all features from the dataframe, dropping the regular cont features and the actual labels\n",
    "all_knn_features = list(data.drop(['y', 'cont1','cont2','cont3','cont4','cont5','cont6','cont7','cont8','cont9','cont10'],axis=1))\n",
    "all_knn_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Loops for the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the excel template\n",
    "knn_df2 = pd.DataFrame(columns=['Your Name',\n",
    "                               'Random State',\n",
    "                               'Class Separator',\n",
    "                               'flip_y',\n",
    "                               'Class weight',\n",
    "                               'Algorithm',\n",
    "                               'k-Neighbors',\n",
    "                               'Type_Features',\n",
    "                               'Number_features',\n",
    "                               'Number of Models',\n",
    "                               'Best F1 Score'])\n",
    "knn_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank list for the scores\n",
    "score = []\n",
    "\n",
    "# create a y variable for the actual labels\n",
    "y = data[\"y\"]\n",
    "\n",
    "# Loop through each k value for # of neighbors\n",
    "for k in range(3,10,2):\n",
    "    # loop through each number of features as i\n",
    "    for i in range(3,8):\n",
    "        #loop through 100 samples\n",
    "        for j in range(1,101):\n",
    "            # select i random features from the list, then make a dataframe of those cols\n",
    "            features = data[random.sample(all_knn_features,i)]            \n",
    "\n",
    "            # initialize blank dfs for the continuous and categorical features\n",
    "            new_df_cat = pd.DataFrame()\n",
    "            new_df_cont = pd.DataFrame()\n",
    "            \n",
    "            # loop through the selected features, and separate them into the new dfs based on cont or cat\n",
    "            for b in features.columns:\n",
    "                if 'cat' in b:\n",
    "                    new_df_cat = pd.concat([new_df_cat, pd.Series(data[b])], axis=1)\n",
    "                else:\n",
    "                    new_df_cont = pd.concat([new_df_cont, pd.Series(data[b])], axis=1)\n",
    "\n",
    "            # if there are no categorical features, create an array of the continuous features\n",
    "            if new_df_cat.empty == True:\n",
    "                work_data = new_df_cont.values\n",
    "    \n",
    "            # if there are no continuous features, create an array of the encoded categorical features\n",
    "            elif new_df_cont.empty == True:\n",
    "                work_data = encoding_func(new_df_cat)\n",
    "    \n",
    "            # If both are present, encode the categorical features, then combine with continuous features\n",
    "            else:\n",
    "                cat_work_data = encoding_func(new_df_cat)\n",
    "                work_data = np.concatenate((new_df_cont.values, cat_work_data), axis=1)\n",
    "            \n",
    "            # Run the knn function, sending # neighbors, features, and the labels -> returns f1 score\n",
    "            f_one = knn(k, work_data, y)\n",
    "            \n",
    "            # add the f1 score to the list\n",
    "            score.append(f_one)\n",
    "\n",
    "        # Create a row for the dataframe for the specific k and i, alongwith the max F1 score, then append to the df\n",
    "        temp = pd.DataFrame([['Name',528552,0.65,0.15,'0.65, 0.35','KNN',k,'Cont + Categorical',i,100,max(score)]],\n",
    "                           columns=list(knn_df2.columns))\n",
    "        knn_df2 = knn_df2.append(temp)\n",
    "        \n",
    "        # reset the score list\n",
    "        score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#3c38a8\">Combine Everything</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join KNN Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the two knn dataframes\n",
    "final_knn_df = pd.concat([knn_df1, knn_df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the table so it looks the same as the template\n",
    "final_knn_df2 = final_knn_df.sort_values(by=['k-Neighbors', 'Type_Features', 'Number_features'], ascending=[True, False, True])\n",
    "final_knn_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the Naive-Bayes Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the NB dataframe to the final dataframe\n",
    "final = pd.concat([final_knn_df2, nb_df])\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir\n",
    "%cd \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe as a .csv\n",
    "final.to_csv(\"Quiz1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
